{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.attentionmlp import AttentionMLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load tokenized data\n",
    "path_dev ='../ECHR_Dataset_Tokenized/legal-bert-base-uncased/df_dev_tokenized.pkl'\n",
    "path_train ='../ECHR_Dataset_Tokenized/legal-bert-base-uncased/df_train_tokenized.pkl'\n",
    "path_test ='../ECHR_Dataset_Tokenized/legal-bert-base-uncased/df_test_tokenized.pkl'\n",
    "\n",
    "df_train = pd.read_pickle(path_train)\n",
    "df_dev = pd.read_pickle(path_dev)\n",
    "df_test = pd.read_pickle(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>LANGUAGEISOCODE</th>\n",
       "      <th>RESPONDENT</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DOCNAME</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>CONCLUSION</th>\n",
       "      <th>JUDGES</th>\n",
       "      <th>text</th>\n",
       "      <th>VIOLATED_ARTICLES</th>\n",
       "      <th>VIOLATED_PARAGRAPHS</th>\n",
       "      <th>VIOLATED_BULLETPOINTS</th>\n",
       "      <th>NON_VIOLATED_ARTICLES</th>\n",
       "      <th>NON_VIOLATED_PARAGRAPHS</th>\n",
       "      <th>NON_VIOLATED_BULLETPOINTS</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-100005</td>\n",
       "      <td>ENG</td>\n",
       "      <td>TUR</td>\n",
       "      <td>ADMISSIBILITY</td>\n",
       "      <td>2010</td>\n",
       "      <td>SHAMSI v. TURKEY</td>\n",
       "      <td>4</td>\n",
       "      <td>Inadmissible</td>\n",
       "      <td>Françoise Tulkens;Ireneu Cabral Barreto;Kristi...</td>\n",
       "      <td>[The applicant, Mr Maher Muhilddin Gazel Al Sh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[tensor(101), tensor(207), tensor(272), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-100024</td>\n",
       "      <td>ENG</td>\n",
       "      <td>ARM</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2010</td>\n",
       "      <td>CASE OF HOVHANNISYAN AND SHIROYAN v. ARMENIA</td>\n",
       "      <td>3</td>\n",
       "      <td>Reminder inadmissible;Violation of P1-1;Just s...</td>\n",
       "      <td>Alvina Gyulumyan;Elisabet Fura;Ineta Ziemele;J...</td>\n",
       "      <td>[4. The applicants were born in 1976, 1973 and...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[tensor(101), tensor(201), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-100026</td>\n",
       "      <td>ENG</td>\n",
       "      <td>ARM</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2010</td>\n",
       "      <td>CASE OF YERANOSYAN AND OTHERS v. ARMENIA</td>\n",
       "      <td>4</td>\n",
       "      <td>Violation of P1-1</td>\n",
       "      <td>Alvina Gyulumyan;Elisabet Fura;Ineta Ziemele;J...</td>\n",
       "      <td>[4. The applicants were born in 1976, 1975, 19...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[tensor(101), tensor(201), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-100029</td>\n",
       "      <td>ENG</td>\n",
       "      <td>RUS</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2010</td>\n",
       "      <td>CASE OF AKHMATKHANOVY v. RUSSIA</td>\n",
       "      <td>4</td>\n",
       "      <td>Violation of Art. 2 (substantive aspect);Viola...</td>\n",
       "      <td>Anatoly Kovler;Christos Rozakis;Dean Spielmann...</td>\n",
       "      <td>[4. The applicants are:, 1) Ms Bilat Akhmatkha...</td>\n",
       "      <td>[13, 2, 3, 5]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(101), tensor(201), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-100038</td>\n",
       "      <td>ENG</td>\n",
       "      <td>NLD</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2010</td>\n",
       "      <td>CASE OF A. v. THE NETHERLANDS</td>\n",
       "      <td>3</td>\n",
       "      <td>Violation of Art. 3 (in case of expulsion to L...</td>\n",
       "      <td>Alvina Gyulumyan;Corneliu Bîrsan;Egbert Myjer;...</td>\n",
       "      <td>[7. The applicant was born in 1972 and lives i...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(101), tensor(204), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ITEMID LANGUAGEISOCODE RESPONDENT         BRANCH  DATE  \\\n",
       "0  001-100005             ENG        TUR  ADMISSIBILITY  2010   \n",
       "1  001-100024             ENG        ARM        CHAMBER  2010   \n",
       "2  001-100026             ENG        ARM        CHAMBER  2010   \n",
       "3  001-100029             ENG        RUS        CHAMBER  2010   \n",
       "4  001-100038             ENG        NLD        CHAMBER  2010   \n",
       "\n",
       "                                        DOCNAME IMPORTANCE  \\\n",
       "0                              SHAMSI v. TURKEY          4   \n",
       "1  CASE OF HOVHANNISYAN AND SHIROYAN v. ARMENIA          3   \n",
       "2      CASE OF YERANOSYAN AND OTHERS v. ARMENIA          4   \n",
       "3               CASE OF AKHMATKHANOVY v. RUSSIA          4   \n",
       "4                 CASE OF A. v. THE NETHERLANDS          3   \n",
       "\n",
       "                                          CONCLUSION  \\\n",
       "0                                       Inadmissible   \n",
       "1  Reminder inadmissible;Violation of P1-1;Just s...   \n",
       "2                                  Violation of P1-1   \n",
       "3  Violation of Art. 2 (substantive aspect);Viola...   \n",
       "4  Violation of Art. 3 (in case of expulsion to L...   \n",
       "\n",
       "                                              JUDGES  \\\n",
       "0  Françoise Tulkens;Ireneu Cabral Barreto;Kristi...   \n",
       "1  Alvina Gyulumyan;Elisabet Fura;Ineta Ziemele;J...   \n",
       "2  Alvina Gyulumyan;Elisabet Fura;Ineta Ziemele;J...   \n",
       "3  Anatoly Kovler;Christos Rozakis;Dean Spielmann...   \n",
       "4  Alvina Gyulumyan;Corneliu Bîrsan;Egbert Myjer;...   \n",
       "\n",
       "                                                text VIOLATED_ARTICLES  \\\n",
       "0  [The applicant, Mr Maher Muhilddin Gazel Al Sh...                []   \n",
       "1  [4. The applicants were born in 1976, 1973 and...                []   \n",
       "2  [4. The applicants were born in 1976, 1975, 19...                []   \n",
       "3  [4. The applicants are:, 1) Ms Bilat Akhmatkha...     [13, 2, 3, 5]   \n",
       "4  [7. The applicant was born in 1972 and lives i...               [3]   \n",
       "\n",
       "  VIOLATED_PARAGRAPHS VIOLATED_BULLETPOINTS NON_VIOLATED_ARTICLES  \\\n",
       "0                  []                    []                    []   \n",
       "1                  []                    []                    []   \n",
       "2                  []                    []                    []   \n",
       "3                  []                    []                    []   \n",
       "4                  []                    []                  [13]   \n",
       "\n",
       "  NON_VIOLATED_PARAGRAPHS NON_VIOLATED_BULLETPOINTS  label  \\\n",
       "0                      []                        []      0   \n",
       "1                      []                        []      0   \n",
       "2                      []                        []      0   \n",
       "3                      []                        []      1   \n",
       "4                      []                        []      1   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [[[tensor(101), tensor(207), tensor(272), tens...   \n",
       "1  [[[tensor(101), tensor(201), tensor(117), tens...   \n",
       "2  [[[tensor(101), tensor(201), tensor(117), tens...   \n",
       "3  [[[tensor(101), tensor(201), tensor(117), tens...   \n",
       "4  [[[tensor(101), tensor(204), tensor(117), tens...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  \n",
       "1  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  \n",
       "2  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  \n",
       "3  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  \n",
       "4  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = df_train[['input_ids', 'attention_mask', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the series into a list\n",
    "input_ids = documents.input_ids.tolist()\n",
    "attention_mask = documents.attention_mask.tolist()\n",
    "labels = documents.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_ids = [torch.stack(i) for i in input_ids]\n",
    "attention_mask = [torch.stack(i) for i in attention_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_ids =[torch.squeeze(i, dim=1) for i in input_ids]\n",
    "attention_mask =[torch.squeeze(i, dim=1) for i in attention_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths =[i.size(0) for i in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "       data: is a list of tuples with (input_ids, attention mask, label, length)\n",
    "    \"\"\"\n",
    "    input_ids = [i[0] for i in data]\n",
    "    attention_mask = [i[1] for i in data]\n",
    "    labels = [i[2] for i in data]\n",
    "    lengths = [i[3] for i in data]\n",
    "\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    max_length = torch.max(lengths)\n",
    "    # pad the input_ids and attention_mask so that they have the same length [max_length, 512]\n",
    "    for i in range(len(input_ids)):\n",
    "        pad = torch.zeros((max_length - lengths[i],512), dtype=torch.long)\n",
    "        input_ids[i] = torch.cat((input_ids[i], pad), dim=0, )\n",
    "        attention_mask[i] = torch.cat((attention_mask[i], pad), dim=0)\n",
    "\n",
    "    return torch.stack(input_ids), torch.stack(attention_mask), labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ECHRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_mask[idx], self.labels[idx], self.input_ids[idx].size(0) # last one is the length of the input_ids, used for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "dataset = ECHRDataset(input_ids, attention_mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=next(iter(dataloader))\n",
    "\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to run the model\n",
    "from transformers import BertModel\n",
    "bert = BertModel.from_pretrained('nlpaueb/legal-bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_mask(data, lengths, batch_first=True):\n",
    "    if batch_first:\n",
    "        max_length = data.size(1)\n",
    "        batch_size = data.size(0)\n",
    "    else:\n",
    "        max_length = data.size(0)\n",
    "        batch_size = data.size(1)\n",
    "    mask = torch.zeros((max_length, batch_size), dtype=torch.bool)\n",
    "\n",
    "    for i, l in enumerate(lengths):\n",
    "        mask[i, :l] = 1.\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "class Hierbert(nn.Module):\n",
    "    def __init__(self, bert, hidden_sizes ):\n",
    "        super(Hierbert, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.attention_mlp = AttentionMLP(768, hidden_sizes)\n",
    "\n",
    "    def forward(self, input_ids, attention_masks, lengths, bert_require_grad=True):\n",
    "\n",
    "        max_l = input_ids.size(1)# inputs are already padded\n",
    "        bert_output=[]\n",
    "\n",
    "        if bert_require_grad:\n",
    "            self.bert.train()\n",
    "        else:\n",
    "            self.bert.eval()\n",
    "\n",
    "        for i in range(max_l):\n",
    "\n",
    "\n",
    "            bert_output.append( self.bert(input_ids[:,i], attention_masks[:,i]).pooler_output )\n",
    "\n",
    "        bert_output = torch.stack(bert_output)\n",
    "\n",
    "        print(bert_output.shape)\n",
    "        sentence_mask = make_mask(input_ids, lengths) \n",
    "\n",
    "        return self.attention_mlp(bert_output.permute(1,0,2), sentence_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
