{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.attentionmlp import AttentionMLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load tokenized data\n",
    "path_dev ='ECHR_Dataset_Tokenized/legal-bert-base-uncased/df_dev_tokenized.pkl'\n",
    "path_train ='ECHR_Dataset_Tokenized/legal-bert-base-uncased/df_dev_tokenized.pkl'\n",
    "path_test ='ECHR_Dataset_Tokenized/legal-bert-base-uncased/df_dev_tokenized.pkl'\n",
    "\n",
    "df_train = pd.read_pickle(path_train)\n",
    "df_dev = pd.read_pickle(path_dev)\n",
    "df_test = pd.read_pickle(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>LANGUAGEISOCODE</th>\n",
       "      <th>RESPONDENT</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DOCNAME</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>CONCLUSION</th>\n",
       "      <th>JUDGES</th>\n",
       "      <th>text</th>\n",
       "      <th>VIOLATED_ARTICLES</th>\n",
       "      <th>VIOLATED_PARAGRAPHS</th>\n",
       "      <th>VIOLATED_BULLETPOINTS</th>\n",
       "      <th>NON_VIOLATED_ARTICLES</th>\n",
       "      <th>NON_VIOLATED_PARAGRAPHS</th>\n",
       "      <th>NON_VIOLATED_BULLETPOINTS</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-100036</td>\n",
       "      <td>ENG</td>\n",
       "      <td>LTU</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2010</td>\n",
       "      <td>CASE OF BALČIŪNAS v. LITHUANIA</td>\n",
       "      <td>4</td>\n",
       "      <td>Violation of Art. 5-3;No violation of Art. 6-1...</td>\n",
       "      <td>Alvina Gyulumyan;Corneliu Bîrsan;Egbert Myjer;...</td>\n",
       "      <td>[7. The applicant was born in 1977 and lives i...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[5-3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[6-1, 6-3]</td>\n",
       "      <td>[6-3-d]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(101), tensor(204), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-100094</td>\n",
       "      <td>ENG</td>\n",
       "      <td>ARM</td>\n",
       "      <td>ADMISSIBILITY</td>\n",
       "      <td>2010</td>\n",
       "      <td>PAPYAN AND DAVTYAN v. ARMENIA</td>\n",
       "      <td>4</td>\n",
       "      <td>Inadmissible</td>\n",
       "      <td>Alvina Gyulumyan;Elisabet Fura;Ineta Ziemele;J...</td>\n",
       "      <td>[1. The applicants, Mr Hayk Papyan, Mr Samvel ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[tensor(101), tensor(198), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-100139</td>\n",
       "      <td>ENG</td>\n",
       "      <td>HUN</td>\n",
       "      <td>COMMITTEE</td>\n",
       "      <td>2010</td>\n",
       "      <td>CASE OF GYARFAS AND HUNAUDIT KFT. v. HUNGARY</td>\n",
       "      <td>4</td>\n",
       "      <td>Violation of Art. 6-1</td>\n",
       "      <td>András Sajó;Kristina Pardalos</td>\n",
       "      <td>[4. The applicant was born in 1956 and lives i...</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[6-1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(101), tensor(201), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-100141</td>\n",
       "      <td>ENG</td>\n",
       "      <td>TUR</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2010</td>\n",
       "      <td>CASE OF ABDOLKHANI AND KARIMNIA v. TURKEY (no. 2)</td>\n",
       "      <td>4</td>\n",
       "      <td>Violation of Art. 3</td>\n",
       "      <td>Françoise Tulkens;Guido Raimondi;Ireneu Cabral...</td>\n",
       "      <td>[4. The applicants were born in 1973 and 1978 ...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[[tensor(101), tensor(201), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-100197</td>\n",
       "      <td>ENG</td>\n",
       "      <td>LTU</td>\n",
       "      <td>CHAMBER</td>\n",
       "      <td>2010</td>\n",
       "      <td>CASE OF GINEITIENE v. LITHUANIA</td>\n",
       "      <td>3</td>\n",
       "      <td>Remainder inadmissible;No violation of Art. 14...</td>\n",
       "      <td>András Sajó;Françoise Tulkens;Guido Raimondi;K...</td>\n",
       "      <td>[5. The applicant was born in 1968 and lives i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[14, 8]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[tensor(101), tensor(202), tensor(117), tens...</td>\n",
       "      <td>[[[tensor(1), tensor(1), tensor(1), tensor(1),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ITEMID LANGUAGEISOCODE RESPONDENT         BRANCH  DATE  \\\n",
       "0  001-100036             ENG        LTU        CHAMBER  2010   \n",
       "1  001-100094             ENG        ARM  ADMISSIBILITY  2010   \n",
       "2  001-100139             ENG        HUN      COMMITTEE  2010   \n",
       "3  001-100141             ENG        TUR        CHAMBER  2010   \n",
       "4  001-100197             ENG        LTU        CHAMBER  2010   \n",
       "\n",
       "                                             DOCNAME IMPORTANCE  \\\n",
       "0                     CASE OF BALČIŪNAS v. LITHUANIA          4   \n",
       "1                      PAPYAN AND DAVTYAN v. ARMENIA          4   \n",
       "2       CASE OF GYARFAS AND HUNAUDIT KFT. v. HUNGARY          4   \n",
       "3  CASE OF ABDOLKHANI AND KARIMNIA v. TURKEY (no. 2)          4   \n",
       "4                    CASE OF GINEITIENE v. LITHUANIA          3   \n",
       "\n",
       "                                          CONCLUSION  \\\n",
       "0  Violation of Art. 5-3;No violation of Art. 6-1...   \n",
       "1                                       Inadmissible   \n",
       "2                              Violation of Art. 6-1   \n",
       "3                                Violation of Art. 3   \n",
       "4  Remainder inadmissible;No violation of Art. 14...   \n",
       "\n",
       "                                              JUDGES  \\\n",
       "0  Alvina Gyulumyan;Corneliu Bîrsan;Egbert Myjer;...   \n",
       "1  Alvina Gyulumyan;Elisabet Fura;Ineta Ziemele;J...   \n",
       "2                      András Sajó;Kristina Pardalos   \n",
       "3  Françoise Tulkens;Guido Raimondi;Ireneu Cabral...   \n",
       "4  András Sajó;Françoise Tulkens;Guido Raimondi;K...   \n",
       "\n",
       "                                                text VIOLATED_ARTICLES  \\\n",
       "0  [7. The applicant was born in 1977 and lives i...               [5]   \n",
       "1  [1. The applicants, Mr Hayk Papyan, Mr Samvel ...                []   \n",
       "2  [4. The applicant was born in 1956 and lives i...               [6]   \n",
       "3  [4. The applicants were born in 1973 and 1978 ...               [3]   \n",
       "4  [5. The applicant was born in 1968 and lives i...                []   \n",
       "\n",
       "  VIOLATED_PARAGRAPHS VIOLATED_BULLETPOINTS NON_VIOLATED_ARTICLES  \\\n",
       "0               [5-3]                    []                   [6]   \n",
       "1                  []                    []                    []   \n",
       "2               [6-1]                    []                    []   \n",
       "3                  []                    []                    []   \n",
       "4                  []                    []               [14, 8]   \n",
       "\n",
       "  NON_VIOLATED_PARAGRAPHS NON_VIOLATED_BULLETPOINTS  label  \\\n",
       "0              [6-1, 6-3]                   [6-3-d]      1   \n",
       "1                      []                        []      0   \n",
       "2                      []                        []      1   \n",
       "3                      []                        []      1   \n",
       "4                      []                        []      0   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [[[tensor(101), tensor(204), tensor(117), tens...   \n",
       "1  [[[tensor(101), tensor(198), tensor(117), tens...   \n",
       "2  [[[tensor(101), tensor(201), tensor(117), tens...   \n",
       "3  [[[tensor(101), tensor(201), tensor(117), tens...   \n",
       "4  [[[tensor(101), tensor(202), tensor(117), tens...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  \n",
       "1  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  \n",
       "2  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  \n",
       "3  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  \n",
       "4  [[[tensor(1), tensor(1), tensor(1), tensor(1),...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = df_train[['input_ids', 'attention_mask', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the series into a list\n",
    "input_ids = documents.input_ids.tolist()\n",
    "attention_mask = documents.attention_mask.tolist()\n",
    "labels = documents.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_ids = [torch.stack(i) for i in input_ids]\n",
    "attention_mask = [torch.stack(i) for i in attention_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_ids =[torch.squeeze(i, dim=1) for i in input_ids]\n",
    "attention_mask =[torch.squeeze(i, dim=1) for i in attention_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths =[i.size(0) for i in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "       data: is a list of tuples with (input_ids, attention mask, label, length)\n",
    "    \"\"\"\n",
    "    input_ids = [i[0] for i in data]\n",
    "    attention_mask = [i[1] for i in data]\n",
    "    labels = [i[2] for i in data]\n",
    "    lengths = [i[3] for i in data]\n",
    "\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    max_length = torch.max(lengths)\n",
    "    # pad the input_ids and attention_mask so that they have the same length [max_length, 512]\n",
    "    for i in range(len(input_ids)):\n",
    "        pad = torch.zeros((max_length - lengths[i],512), dtype=torch.long)\n",
    "        input_ids[i] = torch.cat((input_ids[i], pad), dim=0, )\n",
    "        attention_mask[i] = torch.cat((attention_mask[i], pad), dim=0)\n",
    "\n",
    "    return torch.stack(input_ids), torch.stack(attention_mask), labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ECHRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_mask[idx], self.labels[idx], self.input_ids[idx].size(0) # last one is the length of the input_ids, used for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "dataset = ECHRDataset(input_ids, attention_mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=next(iter(dataloader))\n",
    "\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to run the model\n",
    "from transformers import BertModel\n",
    "bert = BertModel.from_pretrained('nlpaueb/legal-bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_mask(data, lengths, batch_first=True):\n",
    "    if batch_first:\n",
    "        max_length = data.size(1)\n",
    "        batch_size = data.size(0)\n",
    "    else:\n",
    "        max_length = data.size(0)\n",
    "        batch_size = data.size(1)\n",
    "    mask = torch.zeros((max_length, batch_size), dtype=torch.bool)\n",
    "\n",
    "    for i, l in enumerate(lengths):\n",
    "        mask[i, :l] = 1.\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "class Hierbert(nn.Module):\n",
    "    def __init__(self, bert, hidden_sizes ):\n",
    "        super(Hierbert, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.attention_mlp = AttentionMLP(768, hidden_sizes)\n",
    "\n",
    "    def forward(self, input_ids, attention_masks, lengths, bert_require_grad=True):\n",
    "\n",
    "        max_l = input_ids.size(1)# inputs are already padded\n",
    "        bert_output = []\n",
    "\n",
    "        if bert_require_grad:\n",
    "            self.bert.train()\n",
    "        else:\n",
    "            self.bert.eval()\n",
    "\n",
    "        for i in range(max_l):\n",
    "            bert_output.append(\n",
    "                self.bert(input_ids[:,i], attention_masks[:,i]).pooler_output\n",
    "            )\n",
    "\n",
    "        bert_output = torch.stack(bert_output)\n",
    "\n",
    "        print(bert_output.shape)\n",
    "        sentence_mask = make_mask(input_ids, lengths).to('mps') \n",
    "\n",
    "        return self.attention_mlp(bert_output.permute(1,0,2), sentence_mask.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 101,  207,  272,  ...,    0,    0,    0],\n",
       "          [ 101,  207, 2211,  ...,    0,    0,    0],\n",
       "          [ 101,  222,  442,  ...,    0,    0,    0],\n",
       "          [ 101,  222,  554,  ...,    0,    0,    0],\n",
       "          [ 101,  242,  234,  ...,    0,    0,    0]]]),\n",
       " tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]]]),\n",
       " tensor([0]),\n",
       " tensor([5]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 768])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "device = 'mps'\n",
    "model = Hierbert(bert=bert, hidden_sizes=[768,2])\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "accelerator = Accelerator()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "model, optimizer, training_dataloader, scheduler = accelerator.prepare(\n",
    "     model, optimizer, dataloader, scheduler\n",
    ")\n",
    "\n",
    "for batch in training_dataloader:\n",
    "    optimizer.zero_grad()\n",
    "    inputs, att, targets, l = batch\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    outputs = model(inputs, att, l)\n",
    "    loss = loss_function(outputs, targets)\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
