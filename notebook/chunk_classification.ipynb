{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal Judgement Predictor - A classification task on BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "path_to_datasets = 'embeddings_datasets/legal-bert-base-uncased/'\n",
    "path_to_model = 'models/attention-mlp/'\n",
    "create_dataset = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECHRDataset(Dataset):\n",
    "        def __init__(self, data, attention_mask, labels):\n",
    "            self.data = data\n",
    "            self.attention_mask = attention_mask\n",
    "            self.labels = labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx], self.attention_mask[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if create_dataset:\n",
    "        \n",
    "    # pad the data to be of the same shape\n",
    "    def pad_data(data, max_len):\n",
    "        padded_data = []\n",
    "        attention_masks = []\n",
    "        for i in range(len(data)):\n",
    "            attention_masks.append([1] * data[i].shape[0] + [0] * (max_len - data[i].shape[0]))\n",
    "            padded_data.append(F.pad(data[i], (0, 0, 0, max_len - data[i].shape[0])))\n",
    "        #print(len(attention_masks))\n",
    "        return torch.stack(padded_data), torch.tensor(attention_masks)\n",
    "\n",
    "    # load data\n",
    "    train = torch.load('embeddings/legal-bert-base-uncased/emb_tr_cpu.pkl')\n",
    "    dev = torch.load('embeddings/legal-bert-base-uncased/emb_dev_cpu.pkl')\n",
    "    test = torch.load('embeddings/legal-bert-base-uncased/emb_test_cpu.pkl')\n",
    "\n",
    "    print('Train '+str(len(train)),'Dev '+str(len(dev)), 'Test '+str(len(test)))\n",
    "    \n",
    "    # concat dev to train series\n",
    "    train = np.concatenate((train, dev))\n",
    "\n",
    "    print('Train + Dev = '+str(len(train)))\n",
    "\n",
    "    # load labels\n",
    "    train_labels = pd.read_pickle('embeddings/legal-bert-base-uncased/train_labels.pkl')\n",
    "    dev_labels = pd.read_pickle('embeddings/legal-bert-base-uncased/dev_labels.pkl')\n",
    "    test_labels = pd.read_pickle('embeddings/legal-bert-base-uncased/test_labels.pkl')\n",
    "\n",
    "    # concat dev labels to train labels\n",
    "    train_labels = torch.tensor(np.concatenate((train_labels, dev_labels)))\n",
    "\n",
    "    # pad the data\n",
    "    max_len_train = max([x.shape[0] for x in train])\n",
    "    max_len_test = max([x.shape[0] for x in test])\n",
    "    train, train_attention_masks = pad_data(train, max_len_train)\n",
    "    test, test_attention_masks = pad_data(test, max_len_test)\n",
    "\n",
    "    # create the datasets\n",
    "    train_dataset = ECHRDataset(train, train_attention_masks, train_labels)\n",
    "    test_dataset = ECHRDataset(test, test_attention_masks, test_labels)\n",
    "\n",
    "    print (train_dataset.data.device)\n",
    "\n",
    "    # save the datasets\n",
    "    if not os.path.exists(path_to_datasets):\n",
    "        os.makedirs(path_to_datasets)\n",
    "    torch.save(train_dataset, path_to_datasets+'train_dataset.pt')\n",
    "    torch.save(test_dataset, path_to_datasets+'test_dataset.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not create_dataset:\n",
    "    train_dataset = torch.load(path_to_datasets+'train_dataset.pt')\n",
    "    test_dataset = torch.load(path_to_datasets+'test_dataset.pt')\n",
    "    print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing Axes3D for 3D plotting\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "mean_train = np.array([x.mean(0).numpy() for x in train_dataset.data])\n",
    "\n",
    "print(mean_train.shape)\n",
    "\n",
    "train_scaled = scaler.fit_transform(mean_train)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "xpca = pca.fit_transform(train_scaled)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot\n",
    "scatter = ax.scatter(xpca[:, 0], xpca[:, 1], xpca[:, 2], c=train_dataset.labels, cmap='viridis')\n",
    "\n",
    "# Adding legend for positive and negative classes\n",
    "plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Negative'),\n",
    "                    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='orange', markersize=10, label='Positive')],\n",
    "           loc='upper right')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.set_zlabel('PC 3')\n",
    "plt.title('PCA of Train Data')\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(scatter, label='Class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE on avg of chunks\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming you have already defined and scaled mean_train and train_dataset.labels\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_scaled, train_dataset.labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculating metrics\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Random Forest F1:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initializing the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Training the classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculating metrics\n",
    "f1 = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"SVM F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initializing the MLP classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(16,), max_iter=1000, random_state=42)\n",
    "\n",
    "# Training the classifier\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# Calculating metrics\n",
    "f1 = f1_score(y_test, y_pred_mlp, average='weighted')\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "print(\"MLP F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention + MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AttentionMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes, dropout=0, weight_decay=0.01):\n",
    "        super(AttentionMLP, self).__init__()\n",
    "        # vector for query attention\n",
    "        self.selector = nn.parameter.Parameter(torch.randn(input_dim, 1))\n",
    "        self.Value= nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.Key = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        # mlp layers\n",
    "        layers = []\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i + 1]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output = nn.Linear(hidden_sizes[-1], 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        # attention\n",
    "        key = self.Key(x)\n",
    "\n",
    "        value = self.Value(x)\n",
    "\n",
    "        non_normalized_attention = torch.matmul(key, self.selector)\n",
    "        if attention_mask is not None:\n",
    "            attention_mask=attention_mask.unsqueeze(2)\n",
    "\n",
    "            non_normalized_attention = non_normalized_attention.masked_fill(attention_mask == 0, -1e9)\n",
    "        attention = F.softmax(non_normalized_attention, dim=1)\n",
    "        # permute the attention to match the shape of the value\n",
    "        attention = attention.permute(0, 2, 1)\n",
    "\n",
    "        x = torch.matmul(attention, value)\n",
    "\n",
    "        # mlp\n",
    "        x = self.mlp(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to device \n",
    "# check if windows or macos\n",
    "if (torch.cuda.is_available()):\n",
    "    print(\"Running on GPU\")\n",
    "    device = torch.device('cuda')\n",
    "elif (torch.backends.mps.is_available()):\n",
    "    print(\"Running on MPS\")\n",
    "    device = torch.device('mps')\n",
    "else :\n",
    "    print(\"Running on CPU\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "train_dataset.data = train_dataset.data.to(device)\n",
    "train_dataset.labels = train_dataset.labels.to(device)\n",
    "train_dataset.attention_mask = train_dataset.attention_mask.to(device)\n",
    "\n",
    "test_dataset.data = test_dataset.data.to(device)\n",
    "test_dataset.labels = test_dataset.labels.to(device)\n",
    "test_dataset.attention_mask = test_dataset.attention_mask.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the dataloader for the training set\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = AttentionMLP(768, [768,16])\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "epochs = 50\n",
    "k_folds = 5  # Change this according to your preference\n",
    "all_val_accuracies = []\n",
    "\n",
    "# Initialize tqdm progress bar for epochs\n",
    "epoch_progress_bar = tqdm(range(epochs), desc=\"Epochs\", unit=\"epoch\")\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation for this fold\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "    for epoch in epoch_progress_bar:\n",
    "        running_loss = 0.0\n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "        \n",
    "        for i, data in loop:\n",
    "            inputs, att_masks, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, att_masks)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validate the model\n",
    "        with torch.no_grad():\n",
    "            val_running_loss = 0.0\n",
    "            val_predictions = []\n",
    "            val_targets = []\n",
    "            for data in val_loader:\n",
    "                inputs, att_masks, labels = data\n",
    "                outputs = model(inputs, att_masks)\n",
    "                val_loss = criterion(outputs, labels.float())\n",
    "                val_running_loss += val_loss.item()\n",
    "                val_predictions.extend((outputs > 0.5).long().cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "            val_loss = val_running_loss / len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            val_accuracy = accuracy_score(val_targets, val_predictions)\n",
    "            all_val_accuracies.append(val_accuracy)  # Store accuracy for this fold\n",
    "\n",
    "            # Save the model if it's the best so far for val loss\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = model\n",
    "\n",
    "        # Update the description of the epoch progress bar\n",
    "        epoch_progress_bar.set_postfix({\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Val Loss\": val_loss,\n",
    "            \"Val Acc\": val_accuracy\n",
    "        })\n",
    "\n",
    "# Compute the mean validation accuracy across all folds\n",
    "mean_val_accuracy = sum(all_val_accuracies) / len(all_val_accuracies)\n",
    "print(\"Mean Validation Accuracy:\", mean_val_accuracy)\n",
    "\n",
    "# save the best model for val loss \n",
    "import time\n",
    "if not os.path.exists(path_to_model):\n",
    "    os.makedirs(path_to_model)\n",
    "torch.save(best_model, f\"{path_to_model}/{time.time()}-{best_val_loss:.4f}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print traianing and validation loss\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# plot two image by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].plot(train_losses, label='Training loss')\n",
    "ax[0].plot(val_losses, label='Validation loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[1].plot(train_accuracies, label='Training accuracy')\n",
    "ax[1].plot(val_accuracies, label='Validation accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model \n",
    "from torch import load\n",
    "model = load('models/attention-mlp/1709484443.4163241-0.3393.pth')\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the model\n",
    "from sklearn.metrics import classification_report\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_dataset.data, test_dataset.attention_mask)\n",
    "    loss = criterion(outputs, test_dataset.labels.float())\n",
    "    print(f'Test loss: {loss.item()}')\n",
    "    print(classification_report(test_dataset.labels.cpu(), (outputs > 0.5).cpu()))\n",
    "    # confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    cm = confusion_matrix(test_dataset.labels.cpu(), (outputs > 0.5).cpu())\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
